{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a73c620b",
   "metadata": {},
   "source": [
    "# Train bilingual control probes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d8fb5b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2e3fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "talk_tuner_path = \"/root/sandbox/sandbox/bilingual_user_models/talk_tuner\"\n",
    "sys.path.append(talk_tuner_path)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from src.losses import edl_mse_loss\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from src.probes import ProbeClassification, ProbeClassificationMixScaler\n",
    "from src.train_test_utils import train, test\n",
    "import torch.nn as nn\n",
    "\n",
    "import time\n",
    "\n",
    "tic, toc = (time.time, time.time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0d29b2",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6479f1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/venv/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:796: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/root/venv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92deb5863de14512a21bc446c09762c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 5120)\n",
       "    (layers): ModuleList(\n",
       "      (0-39): 40 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (k_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (v_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (o_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=5120, out_features=13824, bias=False)\n",
       "          (up_proj): Linear(in_features=5120, out_features=13824, bias=False)\n",
       "          (down_proj): Linear(in_features=13824, out_features=5120, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((5120,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((5120,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((5120,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=5120, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\"\n",
    "access_token = \"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\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"meta-llama/Llama-2-13b-chat-hf\", use_auth_token=access_token\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-13b-chat-hf\", use_auth_token=access_token\n",
    ")\n",
    "model.half().to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe8414d",
   "metadata": {},
   "source": [
    "## Control Probe [age]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a351df0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "012325d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.probes import LinearProbeClassification\n",
    "import sklearn.model_selection\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adf8c85",
   "metadata": {},
   "source": [
    "### Training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c360de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TrainerConfig:\n",
    "    # optimization parameters\n",
    "    learning_rate = 1e-3\n",
    "    betas = (0.9, 0.95)\n",
    "    weight_decay = 0.1  # only applied on matmul weights\n",
    "    # learning rate decay params: linear warmup followed by cosine decay to 10% of original\n",
    "    # checkpoint settings\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "264a31c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "uncertainty: bool = False\n",
    "logistic: bool = True\n",
    "\n",
    "new_format: bool = True\n",
    "residual_stream: bool = True\n",
    "if_augmented: bool = False\n",
    "remove_last_ai_response: bool = True\n",
    "include_inst: bool = True\n",
    "one_hot: bool = True\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354a1b5a",
   "metadata": {},
   "source": [
    "### Training Utils \n",
    "\n",
    "Need to instantiate a couple of things: \n",
    "1. Map from label to [0, 1]\n",
    "2. Directories to load into the dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92e2e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id_age = {\"child\": 0,\n",
    "                   \"adolescent\": 1,\n",
    "                   \"adult\": 2,\n",
    "                   \"older adult\": 3,\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f830e0e5",
   "metadata": {},
   "source": [
    "### Dataset \n",
    "\n",
    "Load in the TextDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69ce324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.dataset import TextDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040af339",
   "metadata": {},
   "source": [
    "#### [TODO] Mix with spanish dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0514cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../dataset/llama_age_1/\"\n",
    "additional_dataset = [\"../dataset/llama_age_2/\", \"../dataset/openai_age_1/\",\"../dataset/openai_age_2/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1eb1a05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fcaf8813a5249708e153acf4bf1915f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrupted file at ../dataset/openai_age_2/conversation_650_age_adolescent.txt\n",
      "Corrupted file at ../dataset/openai_age_2/conversation_735_age_older adult.txt\n",
      "Corrupted file at ../dataset/openai_age_2/conversation_740_age_child.txt\n"
     ]
    }
   ],
   "source": [
    "dataset = TextDataset(directory, tokenizer, model, label_idf=\"_age_\", label_to_id=label_to_id_age,\n",
    "                        convert_to_llama2_format=True, additional_datas=additional_dataset, \n",
    "                        new_format=new_format, control_probe=True,\n",
    "                        residual_stream=residual_stream, if_augmented=if_augmented, \n",
    "                        remove_last_ai_response=remove_last_ai_response, include_inst=include_inst, k=1,\n",
    "                        one_hot=False, last_tok_pos=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cf4428",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfc06be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id = label_to_id_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4647fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPlit \n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_idx, val_idx = sklearn.model_selection.train_test_split(list(range(len(dataset))), \n",
    "                                                              test_size=test_size,\n",
    "                                                              train_size=train_size,\n",
    "                                                              random_state=12345,\n",
    "                                                              shuffle=True,\n",
    "                                                              stratify=dataset.labels,\n",
    "                                                            )\n",
    "\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "test_dataset = Subset(dataset, val_idx)\n",
    "\n",
    "sampler = None\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, sampler=sampler, pin_memory=True, batch_size=200, num_workers=1)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, pin_memory=True, batch_size=400, num_workers=1)\n",
    "\n",
    "if uncertainty:\n",
    "    loss_func = edl_mse_loss\n",
    "else:\n",
    "    loss_func = nn.BCELoss()\n",
    "\n",
    "torch_device = \"cuda\"\n",
    "\n",
    "accuracy_dict = {}\n",
    "\n",
    "dict_name = \"age\"\n",
    "\n",
    "# seeds = seeds[:9]\n",
    "accuracy_dict[dict_name] = []\n",
    "accuracy_dict[dict_name + \"_final\"] = []\n",
    "accuracy_dict[dict_name + \"_train\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "645b719c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m final_accs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m train_accs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 5\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTOKENIZERS_PARALLELISM\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m41\u001b[39m)):\n\u001b[1;32m      9\u001b[0m     trainer_config \u001b[38;5;241m=\u001b[39m TrainerConfig()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "final_accs = []\n",
    "train_accs = []\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, 41)):\n",
    "    trainer_config = TrainerConfig()\n",
    "    probe = LinearProbeClassification(probe_class=len(label_to_id.keys()), device=\"cuda\", input_dim=5120,\n",
    "                                        logistic=logistic)\n",
    "    optimizer, scheduler = probe.configure_optimizers(trainer_config)\n",
    "    best_acc = 0\n",
    "    max_epoch = 50\n",
    "    verbosity = False\n",
    "    layer_num = i\n",
    "    print(\"-\" * 40 + f\"Layer {layer_num}\" + \"-\" * 40)\n",
    "    for epoch in range(1, max_epoch + 1):\n",
    "        if epoch == max_epoch:\n",
    "            verbosity = True\n",
    "        # Get the train results from training of each epoch\n",
    "        if uncertainty:\n",
    "            train_results = train(probe, torch_device, train_loader, optimizer, \n",
    "                                  epoch, loss_func=loss_func, verbose_interval=None,\n",
    "                                    verbose=verbosity, layer_num=layer_num, \n",
    "                                    return_raw_outputs=True, epoch_num=epoch, num_classes=len(label_to_id.keys()))\n",
    "            test_results = test(probe, torch_device, test_loader, loss_func=loss_func, \n",
    "                                return_raw_outputs=True, verbose=verbosity, layer_num=layer_num,\n",
    "                                scheduler=scheduler, epoch_num=epoch, num_classes=len(label_to_id.keys()))\n",
    "        # TODO: just remove this else case\n",
    "        else:\n",
    "            train_results = train(probe, torch_device, train_loader, optimizer, \n",
    "                                    epoch, loss_func=loss_func, verbose_interval=None,\n",
    "                                    verbose=verbosity, layer_num=layer_num,\n",
    "                                    return_raw_outputs=True,\n",
    "                                    one_hot=args.one_hot, num_classes=len(label_to_id.keys()))\n",
    "            test_results = test(probe, torch_device, test_loader, loss_func=loss_func, \n",
    "                                return_raw_outputs=True, verbose=verbosity, layer_num=layer_num,\n",
    "                                scheduler=scheduler,\n",
    "                                one_hot=args.one_hot, num_classes=len(label_to_id.keys()))\n",
    "\n",
    "        if test_results[1] > best_acc:\n",
    "            best_acc = test_results[1]\n",
    "            torch.save(probe.state_dict(), f\"../probe_checkpoints/controlling_probe/{dict_name}_probe_at_layer_{layer_num}.pth\")\n",
    "    torch.save(probe.state_dict(), f\"../probe_checkpoints/controlling_probe/{dict_name}_probe_at_layer_{layer_num}_final.pth\")\n",
    "    \n",
    "    accs.append(best_acc)\n",
    "    final_accs.append(test_results[1])\n",
    "    train_accs.append(train_results[1])\n",
    "    cm = confusion_matrix(test_results[3], test_results[2])\n",
    "    cm_display = ConfusionMatrixDisplay(cm, display_labels=label_to_id.keys()).plot()\n",
    "    plt.show()\n",
    "\n",
    "    accuracy_dict[dict_name].append(accs)\n",
    "    accuracy_dict[dict_name + \"_final\"].append(final_accs)\n",
    "    accuracy_dict[dict_name + \"_train\"].append(train_accs)\n",
    "    \n",
    "    with open(\"../probe_checkpoints/controlling_probe_experiment.pkl\", \"wb\") as outfile:\n",
    "        pickle.dump(accuracy_dict, outfile)\n",
    "del dataset, train_dataset, test_dataset, train_loader, test_loader\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3502e5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
