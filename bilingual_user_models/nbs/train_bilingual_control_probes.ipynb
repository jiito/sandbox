{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a73c620b",
   "metadata": {},
   "source": [
    "# Train bilingual control probes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d8fb5b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2e3fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "talk_tuner_path = \"/Users/bjar/git/sandbox/bilingual_user_models/talk_tuner\"\n",
    "sys.path.append(talk_tuner_path)\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from losses import edl_mse_loss\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from probes import ProbeClassification, ProbeClassificationMixScaler\n",
    "from train_test_utils import train, test\n",
    "import torch.nn as nn\n",
    "\n",
    "import time\n",
    "\n",
    "tic, toc = (time.time, time.time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0d29b2",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479f1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = \"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\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"meta-llama/Llama-2-13b-chat-hf\", use_auth_token=access_token\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-13b-chat-hf\", use_auth_token=access_token\n",
    ")\n",
    "model.half().cuda()\n",
    "model.eval();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe8414d",
   "metadata": {},
   "source": [
    "## Control Probe [age]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012325d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probes import LinearProbeClassification\n",
    "import sklearn.model_selection\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adf8c85",
   "metadata": {},
   "source": [
    "### Training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c360de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TrainerConfig:\n",
    "    # optimization parameters\n",
    "    learning_rate = 1e-3\n",
    "    betas = (0.9, 0.95)\n",
    "    weight_decay = 0.1  # only applied on matmul weights\n",
    "    # learning rate decay params: linear warmup followed by cosine decay to 10% of original\n",
    "    # checkpoint settings\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264a31c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "\n",
    "class Args(SimpleNamespace):\n",
    "  jump_socioeco = True\n",
    "\n",
    "  new_prompt_format=True\n",
    "  residual_stream=True\n",
    "  uncertainty = False\n",
    "  logistic = True\n",
    "  augmented = False\n",
    "  remove_last_ai_response = True\n",
    "  include_inst = True\n",
    "  one_hot = True\n",
    "\n",
    "args = Args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354a1b5a",
   "metadata": {},
   "source": [
    "### Training Utils \n",
    "\n",
    "Need to instantiate a couple of things: \n",
    "1. Map from label to [0, 1]\n",
    "2. Directories to load into the dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92e2e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id_age = {\"child\": 0,\n",
    "                   \"adolescent\": 1,\n",
    "                   \"adult\": 2,\n",
    "                   \"older adult\": 3,\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f830e0e5",
   "metadata": {},
   "source": [
    "### Dataset \n",
    "\n",
    "Load in the TextDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce324b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TextDataset\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from dataset import TextDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0514cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"dataset/llama_age_1/\"\n",
    "additional_dataset = [\"dataset/llama_age_2/\", \"dataset/openai_age_1/\",\"dataset/openai_age_2/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb1a05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextDataset(directory, tokenizer, model, \n",
    "                      convert_to_llama2_format=True,control_probe=True, k=1,\n",
    "                      one_hot=False, last_tok_pos=-1, **args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cf4428",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfc06be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id = label_to_id_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4647fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPlit \n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_idx, val_idx = sklearn.model_selection.train_test_split(list(range(len(dataset))), \n",
    "                                                              test_size=test_size,\n",
    "                                                              train_size=train_size,\n",
    "                                                              random_state=12345,\n",
    "                                                              shuffle=True,\n",
    "                                                              stratify=dataset.labels,\n",
    "                                                            )\n",
    "\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "test_dataset = Subset(dataset, val_idx)\n",
    "\n",
    "sampler = None\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, sampler=sampler, pin_memory=True, batch_size=200, num_workers=1)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, pin_memory=True, batch_size=400, num_workers=1)\n",
    "\n",
    "if args.uncertainty:\n",
    "    loss_func = edl_mse_loss\n",
    "else:\n",
    "    loss_func = nn.BCELoss()\n",
    "torch_device = \"cuda\"\n",
    "\n",
    "accuracy_dict = {}\n",
    "\n",
    "dict_name = \"age\"\n",
    "\n",
    "# seeds = seeds[:9]\n",
    "accuracy_dict[dict_name] = []\n",
    "accuracy_dict[dict_name + \"_final\"] = []\n",
    "accuracy_dict[dict_name + \"_train\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645b719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(0, 41)):\n",
    "    trainer_config = TrainerConfig()\n",
    "    probe = LinearProbeClassification(probe_class=len(label_to_id.keys()), device=\"cuda\", input_dim=5120,\n",
    "                                        logistic=args.logistic)\n",
    "    optimizer, scheduler = probe.configure_optimizers(trainer_config)\n",
    "    best_acc = 0\n",
    "    max_epoch = 50\n",
    "    verbosity = False\n",
    "    layer_num = i\n",
    "    print(\"-\" * 40 + f\"Layer {layer_num}\" + \"-\" * 40)\n",
    "    for epoch in range(1, max_epoch + 1):\n",
    "        if epoch == max_epoch:\n",
    "            verbosity = True\n",
    "        # Get the train results from training of each epoch\n",
    "        if args.uncertainty:\n",
    "          train_results = train(probe, torch_device, train_loader, optimizer, \n",
    "                                  epoch, loss_func=loss_func, verbose_interval=None,\n",
    "                                    verbose=verbosity, layer_num=layer_num, \n",
    "                                    return_raw_outputs=True, epoch_num=epoch, num_classes=len(label_to_id.keys()))\n",
    "            test_results = test(probe, torch_device, test_loader, loss_func=loss_func, \n",
    "                                return_raw_outputs=True, verbose=verbosity, layer_num=layer_num,\n",
    "                                scheduler=scheduler, epoch_num=epoch, num_classes=len(label_to_id.keys()))\n",
    "        # TODO: just remove this else case\n",
    "        else:\n",
    "            train_results = train(probe, torch_device, train_loader, optimizer, \n",
    "                                    epoch, loss_func=loss_func, verbose_interval=None,\n",
    "                                    verbose=verbosity, layer_num=layer_num,\n",
    "                                    return_raw_outputs=True,\n",
    "                                    one_hot=args.one_hot, num_classes=len(label_to_id.keys()))\n",
    "            test_results = test(probe, torch_device, test_loader, loss_func=loss_func, \n",
    "                                return_raw_outputs=True, verbose=verbosity, layer_num=layer_num,\n",
    "                                scheduler=scheduler,\n",
    "                                one_hot=args.one_hot, num_classes=len(label_to_id.keys()))\n",
    "\n",
    "        if test_results[1] > best_acc:\n",
    "            best_acc = test_results[1]\n",
    "            torch.save(probe.state_dict(), f\"probe_checkpoints/controlling_probe/{dict_name}_probe_at_layer_{layer_num}.pth\")\n",
    "    torch.save(probe.state_dict(), f\"probe_checkpoints/controlling_probe/{dict_name}_probe_at_layer_{layer_num}_final.pth\")\n",
    "    \n",
    "    accs.append(best_acc)\n",
    "    final_accs.append(test_results[1])\n",
    "    train_accs.append(train_results[1])\n",
    "    cm = confusion_matrix(test_results[3], test_results[2])\n",
    "    cm_display = ConfusionMatrixDisplay(cm, display_labels=label_to_id.keys()).plot()\n",
    "    plt.show()\n",
    "\n",
    "    accuracy_dict[dict_name].append(accs)\n",
    "    accuracy_dict[dict_name + \"_final\"].append(final_accs)\n",
    "    accuracy_dict[dict_name + \"_train\"].append(train_accs)\n",
    "    \n",
    "    with open(\"probe_checkpoints/controlling_probe_experiment.pkl\", \"wb\") as outfile:\n",
    "        pickle.dump(accuracy_dict, outfile)\n",
    "del dataset, train_dataset, test_dataset, train_loader, test_loader\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3502e5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
