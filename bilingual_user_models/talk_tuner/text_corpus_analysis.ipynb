{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca9d67d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 conversations\n",
      "Age group distribution:\n",
      "adult          250\n",
      "child          250\n",
      "adolescent     250\n",
      "older adult    250\n",
      "Name: age_group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Load all conversations from dataset directories\n",
    "data = []\n",
    "dataset_paths = [Path(\"dataset/llama_age_1/\"), Path(\"dataset/llama_age_2/\"),]\n",
    "\n",
    "\n",
    "# Iterate through each age group directory\n",
    "for dataset_path in dataset_paths:\n",
    "  for file_path in dataset_path.glob(\"*.txt\"):\n",
    "      try:\n",
    "\n",
    "          with open(file_path, 'r', encoding='utf-8') as f:\n",
    "              conversation = f.read()\n",
    "\n",
    "              _, index, _ , label = file_path.stem.split(\"_\")\n",
    "\n",
    "              conversation_dict = {\n",
    "                  \"conversation\": conversation,\n",
    "                  \"age_group\": label,\n",
    "                  \"index\": index\n",
    "              }\n",
    "              data.append(conversation_dict)\n",
    "              \n",
    "      except Exception as e:\n",
    "          print(f\"Error loading {file_path}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Loaded {len(df)} conversations\")\n",
    "print(f\"Age group distribution:\\n{df['age_group'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61e61ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>age_group</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HUMAN: Hi there! I'm looking for a new restaur...</td>\n",
       "      <td>adult</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HUMAN: Hi! I'm looking for a new TV to buy. Ca...</td>\n",
       "      <td>adult</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HUMAN: Hi there! I'm looking for a new restaur...</td>\n",
       "      <td>adult</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HUMAN: Hi! What is your name?\\nASSISTANT: Hi t...</td>\n",
       "      <td>child</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HUMAN: Hey Assistant, what's up?\\n\\nASSISTANT:...</td>\n",
       "      <td>adolescent</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        conversation   age_group index\n",
       "0  HUMAN: Hi there! I'm looking for a new restaur...       adult    87\n",
       "1  HUMAN: Hi! I'm looking for a new TV to buy. Ca...       adult   126\n",
       "2  HUMAN: Hi there! I'm looking for a new restaur...       adult    25\n",
       "3  HUMAN: Hi! What is your name?\\nASSISTANT: Hi t...       child    21\n",
       "4  HUMAN: Hey Assistant, what's up?\\n\\nASSISTANT:...  adolescent    94"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9318eda0",
   "metadata": {},
   "source": [
    "## Look for token patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "127e0cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "access_token = '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'\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\", token=access_token)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57313575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized 1000 conversations\n",
      "Token count statistics:\n",
      "count    1000.000000\n",
      "mean      444.414000\n",
      "std       180.188247\n",
      "min        28.000000\n",
      "25%       328.000000\n",
      "50%       416.000000\n",
      "75%       530.250000\n",
      "max      1780.000000\n",
      "Name: token_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Tokenize conversations for each row\n",
    "tokenized_conversations = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    conversation = row['conversation']\n",
    "    tokens = tokenizer.encode(conversation)\n",
    "    tokenized_conversations.append({\n",
    "        'age_group': row['age_group'],\n",
    "        'index': row['index'],\n",
    "        'conversation': conversation,\n",
    "        'tokens': tokens,\n",
    "        'token_count': len(tokens)\n",
    "    })\n",
    "\n",
    "# Create DataFrame with tokenized data\n",
    "tokenized_df = pd.DataFrame(tokenized_conversations)\n",
    "print(f\"Tokenized {len(tokenized_df)} conversations\")\n",
    "print(f\"Token count statistics:\\n{tokenized_df['token_count'].describe()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2f5cb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ADULT - Top 20 most frequent tokens (filtered):\n",
      "      token_text  count\n",
      "              's    822\n",
      "             any    737\n",
      "              'm    699\n",
      "           great    677\n",
      "         looking    492\n",
      "              Do    473\n",
      "            more    468\n",
      "             're    456\n",
      " recommendations    456\n",
      "            help    435\n",
      "            like    422\n",
      "             new    412\n",
      "                    412\n",
      "            some    373\n",
      "          sounds    372\n",
      "             out    356\n",
      "             'll    341\n",
      "           there    329\n",
      "            That    323\n",
      "           about    318\n",
      "\n",
      "CHILD - Top 20 most frequent tokens (filtered):\n",
      "token_text  count\n",
      "        's   1228\n",
      "         *   1146\n",
      "         *    880\n",
      "      play    859\n",
      "        so    813\n",
      "      want    721\n",
      "      like    685\n",
      "       Can    664\n",
      "      game    639\n",
      "     about    614\n",
      "         Y    429\n",
      "        oh    397\n",
      "       fun    380\n",
      "       ...    379\n",
      "       're    366\n",
      "        Do    339\n",
      "         O    339\n",
      "       Let    331\n",
      "       one    320\n",
      "      What    307\n",
      "\n",
      "ADOLESCENT - Top 20 most frequent tokens (filtered):\n",
      "token_text  count\n",
      "        's   1307\n",
      "      like    825\n",
      "        so    658\n",
      "       any    523\n",
      "        'm    507\n",
      "      help    493\n",
      "      know    463\n",
      "        't    439\n",
      "         *    433\n",
      "       're    430\n",
      "       out    409\n",
      "         *    367\n",
      "     about    364\n",
      "        Do    363\n",
      "      some    355\n",
      "        It    351\n",
      "        if    342\n",
      "     there    338\n",
      "       fun    332\n",
      "    really    330\n",
      "\n",
      "OLDER ADULT - Top 20 most frequent tokens (filtered):\n",
      "token_text  count\n",
      "        's   1425\n",
      "      help   1173\n",
      "         *   1056\n",
      "        'm   1053\n",
      "         *    844\n",
      "        't    820\n",
      "  computer    782\n",
      "      like    711\n",
      "        Oh    633\n",
      "       see    630\n",
      "        so    591\n",
      "      just    584\n",
      "       're    553\n",
      "        if    540\n",
      "       not    526\n",
      "       any    519\n",
      "     think    473\n",
      "       Can    457\n",
      "       Let    456\n",
      "        It    449\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define tokens to filter out\n",
    "common_tokens_to_filter = {\n",
    "    'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by',\n",
    "    'I', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them',\n",
    "    'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did',\n",
    "    'will', 'would', 'could', 'should', 'can', 'may', 'might', 'must',\n",
    "    'this', 'that', 'these', 'those', 'my', 'your', 'his', 'her', 'its', 'our', 'their',\n",
    "    '.', ',', '!', '?', ';', ':', '\"', \"'\", '(', ')', '[', ']', '{', '}', '-', '_',\n",
    "    ' ', '\\n', '\\t'\n",
    "}\n",
    "\n",
    "# Function to clean conversation text\n",
    "def clean_conversation(text):\n",
    "    # Remove HUMAN: and ASSISTANT: tags and their variations\n",
    "    text = re.sub(r'HUMAN:\\s*', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'ASSISTANT:\\s*', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'Human:\\s*', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'Assistant:\\s*', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'H:\\s*', '', text)\n",
    "    text = re.sub(r'A:\\s*', '', text)\n",
    "    return text\n",
    "\n",
    "# Analyze token frequency by age group\n",
    "age_group_token_analysis = {}\n",
    "\n",
    "for age_group in df['age_group'].unique():\n",
    "    # Get all tokens for this age group\n",
    "    age_group_tokens = []\n",
    "    age_group_data = tokenized_df[tokenized_df['age_group'] == age_group]\n",
    "    \n",
    "    for idx, row in age_group_data.iterrows():\n",
    "        # Clean the conversation text\n",
    "        cleaned_conversation = clean_conversation(row['conversation'])\n",
    "        # Tokenize the cleaned text\n",
    "        tokens = tokenizer.encode(cleaned_conversation)\n",
    "        age_group_tokens.extend(tokens)\n",
    "    \n",
    "    # Count token frequencies\n",
    "    token_counts = Counter(age_group_tokens)\n",
    "    \n",
    "    # Convert to DataFrame and filter out common tokens\n",
    "    token_freq_df = pd.DataFrame([\n",
    "        {'token_id': token_id, 'token_text': tokenizer.decode([token_id]), 'count': count}\n",
    "        for token_id, count in token_counts.items()\n",
    "    ])\n",
    "    \n",
    "    # Filter out common tokens\n",
    "    token_freq_df = token_freq_df[\n",
    "        ~token_freq_df['token_text'].str.strip().isin(common_tokens_to_filter)\n",
    "    ].sort_values('count', ascending=False)\n",
    "    \n",
    "    age_group_token_analysis[age_group] = token_freq_df\n",
    "    \n",
    "    print(f\"\\n{age_group.upper()} - Top 20 most frequent tokens (filtered):\")\n",
    "    print(token_freq_df.head(20)[['token_text', 'count']].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35e9d417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total counts by age group where conversation included the trigger word:\n",
      "adult: 231/250 (92.4%) conversations\n",
      "adolescent: 220/250 (88.0%) conversations\n",
      "child: 169/250 (67.60000000000001%) conversations\n",
      "older adult: 250/250 (100.0%) conversations\n"
     ]
    }
   ],
   "source": [
    "top_trigger_words = {\n",
    "  \"adult\": [\"recommendations\"], \n",
    "  \"adolescent\": [\"like\"],\n",
    "  \"child\": [\"play\"],\n",
    "  \"older adult\": [\"computer\"]\n",
    "}\n",
    "\n",
    "top_trigger_words = {\n",
    "  \"adult\": [\"looking\"], \n",
    "  \"adolescent\": [\"like\"],\n",
    "  \"child\": [\"play\"],\n",
    "  \"older adult\": [\"help\"]\n",
    "}\n",
    "\n",
    "# Check for conversations containing top trigger words and count by age group\n",
    "trigger_word_counts = {}\n",
    "\n",
    "for age_group, trigger_words in top_trigger_words.items():\n",
    "    # Get conversations for this age group\n",
    "    age_group_conversations = df[df['age_group'] == age_group]['conversation']\n",
    "    \n",
    "    count = 0\n",
    "    for conversation in age_group_conversations:\n",
    "        conversation_text = conversation.lower()\n",
    "        \n",
    "        # Check if any of the trigger words appear in the conversation\n",
    "        for trigger_word in trigger_words:\n",
    "            if trigger_word.lower() in conversation_text:\n",
    "                count += 1\n",
    "                break\n",
    "    \n",
    "    trigger_word_counts[age_group] = count\n",
    "\n",
    "# Display results\n",
    "print(\"Total counts by age group where conversation included the trigger word:\")\n",
    "for age_group, count in trigger_word_counts.items():\n",
    "    total_conversations = len(df[df['age_group'] == age_group])\n",
    "    print(f\"{age_group}: {count}/{total_conversations} ({count/total_conversations*100}%) conversations\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b7aa33",
   "metadata": {},
   "source": [
    "1. Try and see how much the success of the probe increases when using these \"trigger\" words on the first turn \n",
    "2. See if training the probe to be more general could help?\n",
    "3. Could you detect these \"confounders\" by doing feature analysis? I.e. old people are are always talking about computers? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5253d88d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "talktuner-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
