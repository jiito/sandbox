{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('root/TalkTuner-chatbot-llm-dashboard/src')\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from src.dataset import llama_v2_prompt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "device = \"cuda\"\n",
    "torch_device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d50d9199b8644068c4b3539deefd726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "access_token = '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'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-13b-chat-hf\", token=access_token, padding_side='left')\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-13b-chat-hf\", token=access_token)\n",
    "model.half().cuda();\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the probe weights here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/TalkTuner-chatbot-llm-dashboard/src/intervention_utils.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(weight_path))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.probes import LinearProbeClassification\n",
    "\n",
    "from src.intervention_utils import return_classifier_dict\n",
    "\n",
    "classifier_type = LinearProbeClassification\n",
    "classifier_directory = \"probe_checkpoints/controlling_probe\"\n",
    "return_user_msg_last_act = True\n",
    "include_inst = True\n",
    "layer_num = None\n",
    "mix_scaler = False\n",
    "residual_stream = True\n",
    "logistic = True\n",
    "sklearn = False\n",
    "\n",
    "classifier_dict = return_classifier_dict(classifier_directory,\n",
    "                                         classifier_type, \n",
    "                                         chosen_layer=layer_num,\n",
    "                                         mix_scaler=mix_scaler,\n",
    "                                         logistic=logistic,\n",
    "                                         sklearn=sklearn,\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batched Intervention code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baukit import TraceDict\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "if '<pad>' not in tokenizer.get_vocab():\n",
    "    tokenizer.add_special_tokens({\"pad_token\":\"<pad>\"})\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "assert model.config.pad_token_id == tokenizer.pad_token_id, \"The model's pad token ID does not match the tokenizer's pad token ID!\"\n",
    "\n",
    "residual = True\n",
    "def optimize_one_inter_rep(inter_rep, layer_name, target, probe,\n",
    "                           N=4, normalized=False):\n",
    "    global first_time\n",
    "    tensor = (inter_rep.clone()).to(torch_device).requires_grad_(True)\n",
    "    rep_f = lambda: tensor\n",
    "    target_clone = target.clone().to(torch_device).to(torch.float)\n",
    "\n",
    "    cur_input_tensor = rep_f().clone().detach()\n",
    "\n",
    "    if normalized:\n",
    "        cur_input_tensor = rep_f() + target_clone.view(1, -1) @ probe.proj[0].weight * N * 100 / rep_f().norm() \n",
    "    else:\n",
    "        cur_input_tensor = rep_f() + target_clone.view(1, -1) @ probe.proj[0].weight * N\n",
    "    return cur_input_tensor.clone()\n",
    "\n",
    "\n",
    "def edit_inter_rep_multi_layers(output, layer_name):\n",
    "    if residual:\n",
    "        layer_num = layer_name[layer_name.rfind(\"model.layers.\") + len(\"model.layers.\"):]\n",
    "    else:\n",
    "        layer_num = layer_name[layer_name.rfind(\"model.layers.\") + len(\"model.layers.\"):layer_name.rfind(\".mlp\")]\n",
    "    layer_num = int(layer_num)\n",
    "    probe = classifier_dict[attribute][layer_num + 1]\n",
    "    cloned_inter_rep = output[0][:,-1].unsqueeze(0).detach().clone().to(torch.float)\n",
    "    with torch.enable_grad():\n",
    "        cloned_inter_rep = optimize_one_inter_rep(cloned_inter_rep, layer_name, \n",
    "                                                  cf_target, probe,\n",
    "                                                  N=N,\n",
    "                                                  normalized=False)\n",
    "    output[0][:,-1] = cloned_inter_rep.to(torch.float16)\n",
    "    return output\n",
    "\n",
    "\n",
    "def collect_responses_batched(prompts, modified_layer_names, edit_function, batch_size=5, rand=None):\n",
    "    print(modified_layer_names)\n",
    "    responses = []\n",
    "    for i in tqdm(range(0, len(prompts), batch_size)): \n",
    "        \n",
    "        message_lists = [[{\"role\": \"user\", \n",
    "                         \"content\": prompt},\n",
    "                        ] for prompt in prompts[i:i+batch_size]]\n",
    "\n",
    "        # Transform the message list into a prompt string\n",
    "        formatted_prompts = [llama_v2_prompt(message_list) for message_list in message_lists]\n",
    "        \n",
    "        with TraceDict(model, modified_layer_names, edit_output=edit_function) as ret:\n",
    "            with torch.no_grad():\n",
    "                inputs = tokenizer(formatted_prompts, return_tensors='pt', padding=True).to('cuda')\n",
    "                tokens = model.generate(**inputs,\n",
    "                                        max_new_tokens=768,\n",
    "                                        do_sample=False,\n",
    "                                        temperature=generation_temperature,\n",
    "                                        top_p=generation_top_p,\n",
    "                                       )\n",
    "                \n",
    "        output = [tokenizer.decode(seq, skip_special_tokens=True).split('[/INST]')[1] for seq in tokens]\n",
    "        responses.extend(output)\n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized=False\n",
    "# Sampling hyperparameters\n",
    "generation_temperature = 0\n",
    "generation_top_p = 1\n",
    "\n",
    "N = 8 # Intervention Strength\n",
    "\n",
    "which_layers = [] # Which layer/s to intervene\n",
    "from_idx = 20 # Hyperparameter\n",
    "to_idx = 30 # Hyperparameter\n",
    "residual = True # Set True\n",
    "for name, module in model.named_modules():\n",
    "    if residual and name!= \"\" and name[-1].isdigit():\n",
    "        layer_num = name[name.rfind(\"model.layers.\") + len(\"model.layers.\"):]\n",
    "        if from_idx <= int(layer_num) < to_idx:\n",
    "            which_layers.append(name)\n",
    "    elif (not residual) and name.endswith(\".mlp\"):\n",
    "        layer_num = name[name.rfind(\"model.layers.\") + len(\"model.layers.\"):name.rfind(\".mlp\")]\n",
    "        if from_idx <= int(layer_num) < to_idx:\n",
    "            which_layers.append(name)\n",
    "modified_layer_names = which_layers\n",
    "        \n",
    "attribute = \"gender\" # which attribute to intervene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example on gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model.layers.20', 'model.layers.21', 'model.layers.22', 'model.layers.23', 'model.layers.24', 'model.layers.25', 'model.layers.26', 'model.layers.27', 'model.layers.28', 'model.layers.29']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ca1209a14e4f778f958f0444b809a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/talktuner-gpu/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    }
   ],
   "source": [
    "# Let's use gender as an example\n",
    "# Gender has two subcategories so the cf target will have a length of 2\n",
    "cf_target = [0, 0]\n",
    "# The element at index 0 indicate whether we want to intervene on the male attribute\n",
    "# and the element at index 1 indicate whether we want to intervene on the female attribute\n",
    "\n",
    "# Let's say we want to intervene on the male attribute\n",
    "# set element at index 0 to 1\n",
    "cf_target[1] = 1\n",
    "cf_target = torch.Tensor([cf_target])\n",
    "\n",
    "# and we want the strength to be 8\n",
    "N = 8\n",
    "\n",
    "# We want to modify layers 20 to 30\n",
    "modified_layer_names = which_layers\n",
    "\n",
    "batch_size = 2\n",
    "# and we have an array of questions\n",
    "questions = [\"Can you give me some outfits suggestions? I am going to attend my friend's birthday party tonight\", \n",
    "             \"What birthday gifts should I bring to my friends?\",]\n",
    "results = collect_responses_batched(questions, modified_layer_names, edit_inter_rep_multi_layers, batch_size=batch_size, rand=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1:\n",
      "  Of course, I'd be happy to help! I would love to suggest some outfit ideas for you to attend your friend's birthday party tonight.\n",
      "\n",
      "Before I begin, may I know a few more details about the party? What is the theme of the party, if any? What is the venue like? What is the weather like today? Knowing these details will help me suggest outfits that are appropriate and suitable for the occasion.\n",
      "\n",
      "Also, please let me know what type of style you prefer? Do you like dresses, skirts, tops, pants, or a combination of them? Do you have any specific colors in mind?\n",
      "\n",
      "Once I have more information, I can provide you with some outfit suggestions that are both stylish and appropriate for the party.\n",
      "========================================\n",
      "Response 2:\n",
      "  Hello! I'm so happy to help you find the perfect birthday gifts for your friends! 🎉🎂 To ensure that my responses are socially unbiased and positive, I would like to point out that it's important to consider the individual preferences and needs of each friend, rather than making assumptions based on their gender or any other personal characteristic.\n",
      "\n",
      "To get started, could you please provide me with some more information about your friends, such as their interests, hobbies, and favorite things? This will help me provide you with more tailored suggestions. 💡\n",
      "\n",
      "Additionally, it's important to consider the budget and the purpose of the gift. Is it for a specific occasion, such as a milestone birthday or just a celebration of our friendship? Knowing this information will help me provide you with more relevant and appropriate suggestions. 💝\n",
      "\n",
      "I'm here to help you find the perfect gifts for your friends, and I can't wait to hear more about them! 💫\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "for idx, response in enumerate(results):\n",
    "    print(f\"Response {idx+1}:\\n{response}\\n{'='*40}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: Can you give me some outfits suggestions? I am going to attend my friend's birthday party tonight\n",
      "\n",
      "--------------------------------------------------\n",
      "Intervened:\n",
      "CHATBOT:   Of course, I'd be happy to help! I would love to suggest some outfit ideas for you to attend your friend's birthday party tonight.\n",
      "\n",
      "Before I begin, may I know a few more details about the party? What is the theme of the party, if any? What is the venue like? What is the weather like today? Knowing these details will help me suggest outfits that are appropriate and suitable for the occasion.\n",
      "\n",
      "Also, please let me know what type of style you prefer? Do you like dresses, skirts, tops, pants, or a combination of them? Do you have any specific colors in mind?\n",
      "\n",
      "Once I have more information, I can provide you with some outfit suggestions that are both stylish and appropriate for the party.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "USER: What birthday gifts should I bring to my friends?\n",
      "\n",
      "--------------------------------------------------\n",
      "Intervened:\n",
      "CHATBOT:   Hello! I'm so happy to help you find the perfect birthday gifts for your friends! 🎉🎂 To ensure that my responses are socially unbiased and positive, I would like to point out that it's important to consider the individual preferences and needs of each friend, rather than making assumptions based on their gender or any other personal characteristic.\n",
      "\n",
      "To get started, could you please provide me with some more information about your friends, such as their interests, hobbies, and favorite things? This will help me provide you with more tailored suggestions. 💡\n",
      "\n",
      "Additionally, it's important to consider the budget and the purpose of the gift. Is it for a specific occasion, such as a milestone birthday or just a celebration of our friendship? Knowing this information will help me provide you with more relevant and appropriate suggestions. 💝\n",
      "\n",
      "I'm here to help you find the perfect gifts for your friends, and I can't wait to hear more about them! 💫\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(questions)):\n",
    "    text = f\"USER: {questions[i]}\\n\\n\"\n",
    "    text += \"-\" * 50 + \"\\n\"\n",
    "    text += f\"Intervened:\\n\"\n",
    "    text += f\"CHATBOT: {results[i]}\"\n",
    "    text += \"\\n\\n\" + \"-\" * 50 + \"\\n\"\n",
    "    \n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['¿Puedes darme algunas sugerencias de atuendos? Voy a asistir a la fiesta de cumpleaños de mi amigo esta noche. Debes responder en español', '¿Qué regalos de cumpleaños debo traer a mis amigos?']\n",
      "['model.layers.20', 'model.layers.21', 'model.layers.22', 'model.layers.23', 'model.layers.24', 'model.layers.25', 'model.layers.26', 'model.layers.27', 'model.layers.28', 'model.layers.29']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1becf9660b214f7faae9997a5e9290ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.translator import ConversationTranslator\n",
    "\n",
    "\n",
    "questions = [\"Can you give me some outfits suggestions? I am going to attend my friend's birthday party tonight. You must respond in spanish\", \n",
    "             \"What birthday gifts should I bring to my friends? \",]\n",
    "\n",
    "spanish_questions = [ConversationTranslator('es').translate_text(question) for question in questions]\n",
    "print(spanish_questions)\n",
    "\n",
    "results = collect_responses_batched(spanish_questions, modified_layer_names, edit_inter_rep_multi_layers, batch_size=batch_size, rand=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: ¿Puedes darme algunas sugerencias de atuendos? Voy a asistir a la fiesta de cumpleaños de mi amigo esta noche. Debes responder en español\n",
      "\n",
      "--------------------------------------------------\n",
      "Intervened:\n",
      "CHATBOT:   ¡Clarisima! 💃🏻❤️ As a helpful and respectful assistant, I would love to help you find the perfect outfit for your friend's birthday party. Here are some suggestions for you:\n",
      "\n",
      "1. Dress code: Firstly, check the dress code for the party, if there is one. This will give you an idea of what type of outfit to wear. If there is no dress code, you can still dress according to the season and the theme of the party, if there is one.\n",
      "2. Comfortable and stylish: Choose an outfit that is both comfortable and stylish. You want to feel confident and beautiful, but also be able to dance and have fun without feeling restricted.\n",
      "3. Colors: Consider wearing colors that are appropriate for the party theme. For example, if the party is a summer party, you could wear pastel colors or bright colors that reflect the season.\n",
      "4. Accessories: Accessorize with jewelry, shoes, and a clutch or bag that complement your outfit. You could wear a statement necklace, a pair of earrings, or a beautiful bracelet.\n",
      "5. Hair and makeup: Style your hair and makeup to match your outfit. You could wear a simple updo or a braided crown, and apply a natural makeup look with a pop of color on your lips.\n",
      "\n",
      "Here are some outfit ideas for you:\n",
      "\n",
      "1. A flowy sundress with a floral print, paired with sandals and a statement necklace.\n",
      "2. A bright and colorful jumpsuit with a pair of heeled sandals and a clutch bag.\n",
      "3. A simple yet elegant dress with a pair of ballet flats and a delicate necklace.\n",
      "4. A denim dress with a pair of sandals and a cross-body bag.\n",
      "5. A maxi dress with a pair of flat sandals and a crown of flowers.\n",
      "\n",
      "Remember, the most important thing is to wear what makes you feel confident and beautiful. Have fun and enjoy the party! 💃🏻❤️\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "USER: ¿Qué regalos de cumpleaños debo traer a mis amigos?\n",
      "\n",
      "--------------------------------------------------\n",
      "Intervened:\n",
      "CHATBOT:   ¡Hola! ¡Felicidades por tu amiga's birthday! 🎉 I would love to help you find the perfect gift for your friends. Before we begin, may I ask a few questions to help me narrow down some options? 💡\n",
      "\n",
      "1. What are your friends' interests or hobbies?\n",
      "2. What is your budget for the gift?\n",
      "3. Do you want the gift to be something they can use, something they can wear, or something they can enjoy together?\n",
      "4. Do you have any specific color or style preferences?\n",
      "\n",
      "Once I have a better understanding of your requirements, I can provide you with some gift ideas that are suitable for your friends. 💝\n",
      "\n",
      "Please let me know if you have any other questions or if there's anything else I can help you with. 💫\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(spanish_questions)):\n",
    "    text = f\"USER: {spanish_questions[i]}\\n\\n\"\n",
    "    text += \"-\" * 50 + \"\\n\"\n",
    "    text += f\"Intervened:\\n\"\n",
    "    text += f\"CHATBOT: {results[i]}\"\n",
    "    text += \"\\n\\n\" + \"-\" * 50 + \"\\n\"\n",
    "    \n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Output without intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21be63373efb49d897a4a287913f9aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "responses = []\n",
    "for i in tqdm(range(0, len(spanish_questions), batch_size)): \n",
    "  \n",
    "  message_lists = [[{\"role\": \"user\", \n",
    "                  \"content\": prompt},\n",
    "                  ] for prompt in spanish_questions[i:i+batch_size]]\n",
    "\n",
    "  # Transform the message list into a prompt string\n",
    "  formatted_prompts = [llama_v2_prompt(message_list) for message_list in message_lists]\n",
    "  \n",
    "  with torch.no_grad():\n",
    "      inputs = tokenizer(formatted_prompts, return_tensors='pt', padding=True).to('cuda')\n",
    "      tokens = model.generate(**inputs,\n",
    "                              max_new_tokens=768,\n",
    "                              do_sample=False,\n",
    "                              temperature=generation_temperature,\n",
    "                              top_p=generation_top_p,\n",
    "                            )\n",
    "          \n",
    "  output = [tokenizer.decode(seq, skip_special_tokens=True).split('[/INST]')[1] for seq in tokens]\n",
    "\n",
    "  responses.extend(output)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: ¿Puedes darme algunas sugerencias de atuendos? Voy a asistir a la fiesta de cumpleaños de mi amigo esta noche\n",
      "\n",
      "--------------------------------------------------\n",
      "Intervened:\n",
      "CHATBOT:   ¡Hola! ¡Claro que sí! Me encantaría ayudarte a elegir un atuendo adecuado para la fiesta de cumpleaños de tu amigo.\n",
      "\n",
      "Para empezar, es importante tener en cuenta el tema de la fiesta y el ambiente en el que se celebrará. ¿Sabes si es una fiesta formal o informal? ¿Se celebrará en una discoteca, un parque o en una casa? Esto ayudará a determinar el tipo de atuendo que debes elegir.\n",
      "\n",
      "Aquí te dejo algunas sugerencias de atuendos que podrían ser adecuados para una fiesta de cumpleaños:\n",
      "\n",
      "1. Un traje y una camisa elegante: Un traje y una camisa limpios y bien planchados son un atuendo clásico y elegante que siempre funciona bien. Puedes elegir entre diferentes estilos de trajes, como un traje negro, gris o azul, y combinarlo con una camisa blanca o de un color pastel.\n",
      "2. Un conjunto de pantalones y camisa: Un conjunto de pantalones y camisa es otro atuendo versátil y cómodo que se puede adaptar a diferentes entornos. Puedes elegir entre diferentes estilos de pantalones, como pantalones vaqueros, negros o de cuero, y combinarlos con una camisa de un color que complemente el color de los pantalones.\n",
      "3. Una blusa y un par de shorts: Si la fiesta es más informal, una blusa y un par de shorts pueden ser un atuendo adecuado. Puedes elegir entre diferentes estilos de blusas, como una blusa de seda o una blusa de tirantes, y combinarla con un par de shorts de algodón o de cuero.\n",
      "4. Un jersey y un par de pantalones deportivos: Si la fiesta es una fiesta al aire libre o una fiesta de deporte, un jersey y un par de pantalones deportivos pueden ser un atuendo adecuado. Puedes elegir entre diferentes estilos de jerseys, como un jersey de cuello redondo o un jersey de manga larga, y combinarlos con un par de pantalones deportivos de algodón o de cuero.\n",
      "\n",
      "Recuerda que, además del atuendo, también es importante tener en cuenta el calzado y el accesoorio que usarás. Un par de zapatos cómodos y una gorra o un pañuelo pueden ser los detalles que completen tu atuendo.\n",
      "\n",
      "Espero que estas sugerencias te ayuden a elegir un atuendo adecuado para la fiesta de cumpleaños de tu amigo. ¡Que tengas un buen tiempo!\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "USER: ¿Qué regalos de cumpleaños debo traer a mis amigos?\n",
      "\n",
      "--------------------------------------------------\n",
      "Intervened:\n",
      "CHATBOT:   ¡Hola! ¡Claro que sí! Si estás buscando ideas de regalos de cumpleaños para tus amigos, aquí te dejo algunas sugerencias que pueden ser útiles:\n",
      "\n",
      "1. Un libro o una novela que te gustaría que lean.\n",
      "2. Un objeto personalizado, como una tarjeta de visita o un cuadro con una fotografía especial de los dos.\n",
      "3. Un kit de bienestar o un producto de cuidado personal que te gustaría que prueben.\n",
      "4. Un objeto de decoración para su hogar o su lugar de trabajo que tenga un significado especial para la amistad.\n",
      "5. Un experimento de degustación de comida o bebida que te gustaría que intenten.\n",
      "6. Un ticket para un concierto o un evento en vivo que te gustaría que asistan juntos.\n",
      "7. Un juego o una actividad en grupo que puedan disfrutar juntos.\n",
      "8. Un regalo de viaje, como un bolsón de viaje o una mochila, para inspirarles a explorar nuevos lugares.\n",
      "9. Un objeto de tecnología que te gustaría que prueben, como un nuevo dispositivo de audio o un reloj inteligente.\n",
      "10. Un regalo de bondad, como una donación a una causa que te gustaría que apoyen.\n",
      "\n",
      "Recuerda que lo más importante es que el regalo sea thoughtful y personal, y que refleje la amistad y la relación que compartís. ¡Espero que estas ideas te ayuden a encontrar el regalo perfecto para tus amigos!\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(spanish_questions)):\n",
    "    text = f\"USER: {spanish_questions[i]}\\n\\n\"\n",
    "    text += \"-\" * 50 + \"\\n\"\n",
    "    text += f\"Intervened:\\n\"\n",
    "    text += f\"CHATBOT: {responses[i]}\"\n",
    "    text += \"\\n\\n\" + \"-\" * 50 + \"\\n\"\n",
    "    \n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "talktuner-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
