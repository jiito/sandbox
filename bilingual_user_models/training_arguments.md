# Training Process Arguments Explainer

This document describes the key arguments used throughout the bilingual control probe training workflow, including notebook-level flags in `Args` and parameters passed to the `train` and `test` utilities.

---

## Notebook-level Flags (Args)

- **jump_socioeco** (bool)

  - When `true`, skip or disable socioeconomic-group controls in the dataset generation.
  - Socioeconomic-group controls are stratification or balancing mechanisms applied to the data to ensure examples across different socioeconomic statuses are evenly represented; bypassing these controls means the dataset may be imbalanced with respect to socioeconomic status.

- **new_prompt_format** (bool)

  - Toggle between legacy and the updated prompt templates when generating inputs for the model.

- **residual_stream** (bool)

  - If enabled, include or leverage residual-stream token positions rather than just final token outputs.

- **uncertainty** (bool)

  - Switch the loss to an uncertainty-aware function (`edl_mse_loss`) and compute per-sample uncertainty estimates during training and evaluation.

- **logistic** (bool)

  - Instantiate probes as logistic regressors (sigmoid output) instead of plain linear classifiers.

- **augmented** (bool)

  - Include data augmentations or synthetic variants when building the dataset.

- **remove_last_ai_response** (bool)

  - Strip the model’s prior reply from the prompt context to prevent leakage when constructing control probes.

- **include_inst** (bool)

  - Prepend task instructions to each prompt example, enabling instruction-conditioning of the probe.

- **one_hot** (bool)
  - Encode target labels as one-hot vectors instead of integer indices.
  - One-hot targets are required for certain loss functions (e.g., evidential-deep-learning MSE loss) that expect vector targets and enable modeling per-class probability distributions and uncertainty; they provide proper gradient signals for multi-class classification.

---

## `train` / `test` Utility Parameters

These arguments are accepted by the `train(probe, device, loader, optimizer, epoch, loss_func, ...)` and `test(probe, device, loader, loss_func, ...)` functions.

- **layer_num** (int, default 40)

  - Selects which hidden-state layer index to extract from the model’s activations for probing.

- **return_raw_outputs** (bool, default False)

  - When `true`, returns full model outputs (pre-argmax) alongside predictions and labels for downstream metrics (e.g., AUC or confusion matrices).

- **one_hot** (bool, default False)

  - Mirror of the notebook flag; if enabled, performs one-hot conversion of integer targets before loss computation.

- **uncertainty** (bool, default False)

  - If enabled, computes both class predictions and a scalar uncertainty score per sample via `calc_prob_uncertinty`.

- **verbose_interval** (int or `None`, default 5)

  - Controls how often (in batches) to print intermediate training progress; set to `None` to silence batch-level logs.

- **scheduler** (`torch.optim.lr_scheduler` or `None`)

  - Learning-rate scheduler stepped on validation/test loss each epoch when provided to `test`.

- **class_names** (list of str or `None`)

  - Optional list used for reporting or mapping class indices to human-readable labels in classification reports.

- **report** (bool, default False)

  - If `true`, prints a detailed classification report (precision, recall, F1) at end of training.

- **head** (any, default None)

  - Placeholder for multi-head probe architectures; unused in single-head setups but reserved for future extension.

- **kwargs**
  - Any additional keyword arguments (e.g., `num_classes`) are forwarded to the loss function or one-hot conversion routines.

---

_This file was autogenerated to assist in understanding and configuring the bilingual control probe training pipeline._
