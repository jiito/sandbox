{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa1acedd",
   "metadata": {},
   "source": [
    "## Testing the resiliance of LLMs to stylistic changes..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e126e9f",
   "metadata": {},
   "source": [
    "RQ1: why do LLMs seem to be brittle to changes in \"non-relevant\" information? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49edcbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "from perturbation import language\n",
    "from utils import helpers \n",
    "import torch\n",
    "import sys\n",
    "import transformers\n",
    "from huggingface_hub import login\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af712796",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SimpleNamespace(\n",
    "    attribute=\"whitespace\",\n",
    "    dataset_name=\"oncqa\",\n",
    "    model=\"llama3\",\n",
    "    testing=False,\n",
    "    output_dir=\"/workspace/sandbox/mats9/data\",\n",
    "    output_suffix=\"-oncqa-whitespace_augs\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b0ac9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = helpers.get_dataset(args.dataset_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bde4317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "cuda available True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f1077304984992864223b9c81fd680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "hf_token = \"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\"\n",
    "\n",
    "login(hf_token, add_to_git_credential=True)\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "print(\"cuda available\", torch.cuda.is_available())\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    ")\n",
    "\n",
    "transformers.set_seed(0)\n",
    "client = pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12258ceb",
   "metadata": {},
   "source": [
    "### Get the basic bench from the paper running "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ba1ed59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/medium-is-message/code/perturbation/language.py:185: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ungendered_cancer_df['Input'] = ungendered_cancer_df['Input'].apply(lambda x: x.split(\"Patient message:\", 1)[-1].strip() if \"Patient message:\" in x else x)\n",
      "  0%|          | 0/61 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  2%|▏         | 1/61 [00:04<04:28,  4.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  3%|▎         | 2/61 [00:08<04:15,  4.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  5%|▍         | 3/61 [00:12<03:59,  4.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  7%|▋         | 4/61 [00:16<03:52,  4.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  8%|▊         | 5/61 [00:20<03:46,  4.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 10%|▉         | 6/61 [00:24<03:47,  4.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 11%|█▏        | 7/61 [00:28<03:35,  3.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 13%|█▎        | 8/61 [00:32<03:29,  3.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 15%|█▍        | 9/61 [00:37<03:39,  4.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 16%|█▋        | 10/61 [00:41<03:35,  4.23s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 18%|█▊        | 11/61 [00:45<03:25,  4.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 20%|█▉        | 12/61 [00:49<03:17,  4.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 21%|██▏       | 13/61 [00:52<03:04,  3.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 23%|██▎       | 14/61 [00:56<03:02,  3.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 25%|██▍       | 15/61 [01:00<02:59,  3.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 26%|██▌       | 16/61 [01:04<02:50,  3.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 28%|██▊       | 17/61 [01:08<02:53,  3.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 30%|██▉       | 18/61 [01:11<02:39,  3.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 31%|███       | 19/61 [01:14<02:30,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 33%|███▎      | 20/61 [01:18<02:28,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 34%|███▍      | 21/61 [01:21<02:21,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 36%|███▌      | 22/61 [01:25<02:18,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 38%|███▊      | 23/61 [01:29<02:21,  3.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 39%|███▉      | 24/61 [01:33<02:15,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 41%|████      | 25/61 [01:36<02:12,  3.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 43%|████▎     | 26/61 [01:40<02:13,  3.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 44%|████▍     | 27/61 [01:44<02:10,  3.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 46%|████▌     | 28/61 [01:48<02:01,  3.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 48%|████▊     | 29/61 [01:52<02:00,  3.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 49%|████▉     | 30/61 [01:55<01:52,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 51%|█████     | 31/61 [01:58<01:47,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 52%|█████▏    | 32/61 [02:02<01:45,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 54%|█████▍    | 33/61 [02:07<01:50,  3.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 56%|█████▌    | 34/61 [02:10<01:43,  3.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 57%|█████▋    | 35/61 [02:13<01:33,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 59%|█████▉    | 36/61 [02:17<01:32,  3.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 61%|██████    | 37/61 [02:19<01:16,  3.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 62%|██████▏   | 38/61 [02:23<01:16,  3.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 64%|██████▍   | 39/61 [02:26<01:11,  3.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 66%|██████▌   | 40/61 [02:30<01:12,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 67%|██████▋   | 41/61 [02:34<01:11,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 69%|██████▉   | 42/61 [02:38<01:09,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 70%|███████   | 43/61 [02:41<01:01,  3.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 72%|███████▏  | 44/61 [02:43<00:53,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 74%|███████▍  | 45/61 [02:47<00:53,  3.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 75%|███████▌  | 46/61 [02:50<00:48,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 77%|███████▋  | 47/61 [02:54<00:47,  3.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 79%|███████▊  | 48/61 [02:56<00:41,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 80%|████████  | 49/61 [03:00<00:38,  3.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 82%|████████▏ | 50/61 [03:03<00:34,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 84%|████████▎ | 51/61 [03:09<00:40,  4.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 85%|████████▌ | 52/61 [03:14<00:39,  4.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 87%|████████▋ | 53/61 [03:18<00:33,  4.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 89%|████████▊ | 54/61 [03:25<00:35,  5.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 90%|█████████ | 55/61 [03:29<00:29,  4.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 92%|█████████▏| 56/61 [03:34<00:23,  4.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 93%|█████████▎| 57/61 [03:39<00:19,  4.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 95%|█████████▌| 58/61 [03:41<00:12,  4.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 97%|█████████▋| 59/61 [03:46<00:08,  4.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 98%|█████████▊| 60/61 [03:49<00:04,  4.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "100%|██████████| 61/61 [03:55<00:00,  3.86s/it]\n"
     ]
    }
   ],
   "source": [
    "output_df = language.colorful_add(df, client, args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63ed67b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pin ActiveOrSurveill Gender  Age GenderSpecificCancer  \\\n",
      "0    0                A      M   55                   no   \n",
      "2    2                A      M   68                   no   \n",
      "4    4                A      M   39                   no   \n",
      "5    5                A      F   58                   no   \n",
      "6    6                A      M   64                   no   \n",
      "\n",
      "                                          orig_input  \\\n",
      "0  I've been feeling more fatigued than usual for...   \n",
      "2  I've been experiencing severe diarrhea for the...   \n",
      "4  I've developed a persistent cough and shortnes...   \n",
      "5  I've been experiencing severe nausea and vomit...   \n",
      "6  I've been experiencing persistent lower back p...   \n",
      "\n",
      "                                      whitespace_aug  \n",
      "0  Sample 1 (active treatment):\\nEHR Context:\\nAg...  \n",
      "2  Sample 3 (active treatment):\\nEHR Context:\\nAg...  \n",
      "4  Sample 5 (active treatment):\\nEHR Context:\\nAg...  \n",
      "5  Sample 6 (active treatment):\\nEHR Context:\\nAg...  \n",
      "6  Sample 7 (active treatment):\\nEHR Context:\\nAg...  \n"
     ]
    }
   ],
   "source": [
    "out_path = helpers.make_file_path(args.output_dir, f\"{args.attribute}_aug\", suffix=args.output_suffix)\n",
    "\n",
    "print(output_df.head())\n",
    "output_df.to_csv(out_path, index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d52d18e",
   "metadata": {},
   "source": [
    "### Test this in non-clinical texts? (Another benchmark?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b0e6cb",
   "metadata": {},
   "source": [
    "### DO perturbations affect the accuracy of linear probes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835cd664",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
